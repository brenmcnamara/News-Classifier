{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Classifier\n",
    "\n",
    "**Note: There are some random processes within this notebook, so different runs of the notebook may result in different outcomes.**\n",
    "\n",
    "**Note: This notebook assumes the data being loaded has already been randomly shuffled.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data_utils import BOWEncoding, WordEmbeddingEncoding, WordTokenDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will circle back and add support for embedding layer.\n",
    "# embeddings = data_utils.load_embeddings('./data/glove.6B/glove.6B.100d.txt',\n",
    "#                                         embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('./data/train_data.json', orient='records')\n",
    "data = data.sample(frac=1)\n",
    "data = data.iloc[:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.95\n",
    "split_idx = math.floor(len(data) * train_test_split)\n",
    "\n",
    "train_data = data.iloc[0:split_idx]\n",
    "valid_data = data.iloc[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_encoding = BOWEncoding(data, min_word_freq=5)\n",
    "bow_encoding.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train_dataset = WordTokenDataset(train_data, bow_encoding)\n",
    "bow_train_dataset.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_valid_dataset = WordTokenDataset(valid_data, bow_encoding)\n",
    "bow_valid_dataset.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Should find ways to make this faster. Vectorization? Caching?\n",
    "\n",
    "def create_bow_batched_sequences(samples):\n",
    "    encoding_dim = samples.vocab_size + 1 # Add 1 for EOS token.\n",
    "    sequence_len = samples.longest_sequence + 1 # Add 1 for EOS token.\n",
    "    batch_size = len(samples.label)\n",
    "\n",
    "    sequences = []\n",
    "    # First pass, initialize sequences and matrices.\n",
    "    for t in range(sequence_len):\n",
    "        bow_batch = torch.zeros(size=(batch_size, encoding_dim), dtype=torch.float)\n",
    "        sequences.append(bow_batch)\n",
    "\n",
    "    # Looping through each token in each example. This is slow.\n",
    "    for i, start_offset in enumerate(samples.offset):\n",
    "\n",
    "        end_offset = None if (i+1) >= len(samples.offset) else samples.offset[i+1]\n",
    "        sequence_slice = samples.sequence[start_offset:] if end_offset is None else samples.sequence[start_offset:end_offset]\n",
    "\n",
    "        for j, token_idx in enumerate(sequence_slice):\n",
    "            # jth token in ith example.\n",
    "            sequences[j][i, token_idx] = 1.\n",
    "\n",
    "        j += 1\n",
    "\n",
    "        while j < sequence_len:\n",
    "            # Set EOS one-hot encodings, padded at the end of each sequence.\n",
    "            sequences[j][i, encoding_dim - 1] = 1.\n",
    "            j += 1\n",
    "        \n",
    "    return sequences\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, encoding, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoding = encoding\n",
    "        \n",
    "        self.input_size = encoding.n_inputs() + 1 # Add 1 for EOS token.\n",
    "        self.output_size = encoding.n_classes()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2o = nn.Linear(self.input_size + hidden_size, self.output_size)\n",
    "        self.i2h = nn.Linear(self.input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        # nn.LogSoftmax vs F.log_softmax??\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat([input, hidden], dim=1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(size=(batch_size, self.hidden_size), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, samples):\n",
    "    bow_sequences = create_bow_batched_sequences(samples)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(batch_size = len(samples))\n",
    "        for input in bow_sequences:\n",
    "            output, hidden = model(input, hidden)\n",
    "\n",
    "    max_val, max_idx = torch.max(output, axis=1)\n",
    "        \n",
    "    correct = torch.sum(samples.label == max_idx)\n",
    "    total = len(samples.label)\n",
    "    accuracy = float(correct) / total\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, dataset, data_loader, epochs, logs=True):\n",
    "    training_losses = []\n",
    "    \n",
    "    full_batch_size = data_loader.batch_size\n",
    "\n",
    "    total_loss = 0\n",
    "    print_every = 50\n",
    "    iter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "\n",
    "        for samples in data_loader:\n",
    "            # Note: At the end of the epoch, the final set of samples could be\n",
    "            # smaller than a full batch. This will cause errors with the hidden\n",
    "            # unit, which is working with the full batch size. Will skip this\n",
    "            # training round.\n",
    "            batch_size = len(samples.label)\n",
    "            if batch_size != full_batch_size:\n",
    "                break\n",
    "\n",
    "            iter += 1\n",
    "\n",
    "            bow_sequences = create_bow_batched_sequences(samples)\n",
    "\n",
    "            hidden = model.init_hidden(batch_size=data_loader.batch_size)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for input in bow_sequences:\n",
    "                output, hidden = model(input, hidden)              \n",
    "\n",
    "            loss = criterion(output, samples.label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if iter % print_every == print_every - 1:\n",
    "                print(f'Loss: {total_loss}')\n",
    "                total_loss = 0\n",
    "\n",
    "        \n",
    "    return model, training_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_list = [\n",
    "    {\n",
    "        'batch_size': 100,\n",
    "        'lr': 0.001,\n",
    "        'hidden_dim': 128,        \n",
    "    },\n",
    "    {\n",
    "        'batch_size': 100,\n",
    "        'lr': 0.0001,\n",
    "        'hidden_dim': 128,        \n",
    "    },\n",
    "    {\n",
    "        'batch_size': 1000,\n",
    "        'lr': 0.001,\n",
    "        'hidden_dim': 128,        \n",
    "    },\n",
    "    {\n",
    "        'batch_size': 1000,\n",
    "        'lr': 0.0001,\n",
    "        'hidden_dim': 128,\n",
    "    },\n",
    "        {\n",
    "        'batch_size': 100,\n",
    "        'lr': 0.001,\n",
    "        'hidden_dim': 512,        \n",
    "    },\n",
    "    {\n",
    "        'batch_size': 100,\n",
    "        'lr': 0.0001,\n",
    "        'hidden_dim': 512,        \n",
    "    },\n",
    "    {\n",
    "        'batch_size': 1000,\n",
    "        'lr': 0.001,\n",
    "        'hidden_dim': 512,        \n",
    "    },\n",
    "    {\n",
    "        'batch_size': 1000,\n",
    "        'lr': 0.0001,\n",
    "        'hidden_dim': 512,\n",
    "    }, \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainin Model 1 / 8...\n",
      "Epoch 1\n",
      "Loss: 176.13814783096313\n",
      "Ran in 2.19m\n",
      "Trainin Model 2 / 8...\n",
      "Epoch 1\n",
      "Loss: 181.73610067367554\n",
      "Ran in 3.51m\n",
      "Trainin Model 3 / 8...\n",
      "Epoch 1\n",
      "Ran in 7.68m\n",
      "Trainin Model 4 / 8...\n",
      "Epoch 1\n",
      "Ran in 6.13m\n",
      "Trainin Model 5 / 8...\n",
      "Epoch 1\n",
      "Loss: 202.9548192024231\n",
      "Ran in 5.14m\n",
      "Trainin Model 6 / 8...\n",
      "Epoch 1\n",
      "Loss: 175.26620054244995\n",
      "Ran in 6.99m\n",
      "Trainin Model 7 / 8...\n",
      "Epoch 1\n",
      "Ran in 25.98m\n",
      "Trainin Model 8 / 8...\n",
      "Epoch 1\n",
      "Ran in 26.06m\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "epochs = 1\n",
    "\n",
    "for i, hyperparams in enumerate(hyperparams_list):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f'Trainin Model {i+1} / {len(hyperparams_list)}...')\n",
    "\n",
    "    lr = hyperparams['lr']\n",
    "    batch_size = hyperparams['batch_size']\n",
    "    hidden_dim = hyperparams['hidden_dim']\n",
    "\n",
    "    bow_train_data_loader = DataLoader(dataset=bow_train_dataset,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=False,\n",
    "                                       collate_fn=data_utils.collate_samples)\n",
    "\n",
    "    model = Model(bow_encoding, hidden_size=hidden_dim)\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model, training_losses = train(model, criterion, optimizer, bow_train_dataset, bow_train_data_loader, epochs)\n",
    "    models.append(model)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f'Ran in {(end_time - start_time)/60:.02f}m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran in 0.57m.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for model in models:\n",
    "    samples = bow_valid_dataset[:]\n",
    "    accuracies.append(calculate_accuracy(model, samples))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Ran in {(end_time - start_time)/60:.02f}m.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is #1 with validation accuracy of 14.60%\n"
     ]
    }
   ],
   "source": [
    "best_acc = max(accuracies)\n",
    "best_acc_idx = accuracies.index(best_acc)\n",
    "best_model = models[best_acc_idx]\n",
    "\n",
    "print(f'Best model is #{best_acc_idx+1} with validation accuracy of {best_acc*100:.02f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
